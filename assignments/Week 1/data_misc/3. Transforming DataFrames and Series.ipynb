{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Transforming DataFrames and Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we load a dataframe from a csv we can specify the columns we want to use with `usecols`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"room_id\", \"host_id\", \"room_type\", \"neighborhood\", \"reviews\", \"overall_satisfaction\",\n",
    "               \"accommodates\", \"bedrooms\", \"price\"]\n",
    "\n",
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows and columns\n",
    "To remove rows and columns we can use `.drop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to drop rows and columns from a DataFrame, you can use the function [drop](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html). By default `.loc` removes rows based on the index value.\n",
    "\n",
    "Drop has two important arguments:\n",
    "* inplace: with this argument, you can chose if you want to transform the original DataFrame or if you want the drop function to return a copy of the transformed DataFrame. It\"s default value is False, i.e, you don\"t apply the transformation in the original DataFrame. You\"ll see this argument in many functions that transform DataFrames. **This is usually not recommended**\n",
    "* axis: with this argument, you chose if you want to drop rows (axis=0) or if you want to drop columns (axis=1). The default behaviour is to drop rows. You\"ll se this argument in many functions that transform DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can remove the row with index 6499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df.drop(6499)\n",
    "print(6499 in df.index)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use `inplace=True` we modify the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(6499, inplace=True)\n",
    "print(6499 in df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with `loc` or `iloc`, we can drop multiple rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop([29720, 29891])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use `axis=1` we remove columns (columns are the second axis on a dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop([\"reviews\", \"price\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Reference versus Copy\n",
    "\n",
    "When we assign a dataframe to a new variable, it is important to know that the new dataframe is just a reference to the original one. Thus, **modifying the new dataframe will modify the original and the other way around!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df\n",
    "df.drop([\"room_type\", \"neighborhood\", \"overall_satisfaction\"], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we want to modify a dataframe and make sure we arent modifying the original one, we can use `.copy()` that returns a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "df.drop([\"room_type\", \"neighborhood\", \"overall_satisfaction\"], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math operations with Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication\n",
    "\n",
    "You can either use the `*` or the `multiply()` method to multiply columns or multiply columns by a number.\n",
    "\n",
    "For example, we can calculate the weekly price for the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()\n",
    "df[\"price_per_week\"] = df.price.multiply(7) # o df[\"price_per_week\"] = df.price * 7\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division\n",
    "We can use either `/` or `divide` to divide.\n",
    "\n",
    "For example, we can calculate the number of people per bedroom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"people_per_bedroom\"] = df.accommodates.divide(df.bedrooms)\n",
    "# df[\"people_per_bedroom\"] = df.accommodates / df.bedrooms\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the name of the columns simply assigning a new list to `df.columns`. For example, we can rename the columns and make them capitalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Host_id', 'Room_type', 'Neighborhood', 'Reviews',\n",
    "       'Overall_satisfaction', 'Accommodates', 'Bedrooms', 'Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can delete columns with `drop`, but we can also use the python method `del`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those columns that are strings have a set of special methods, available under the `.str` name.\n",
    "\n",
    "For example, if we want to set the neighbourhood name to lower case, we can use `.str.lower()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.neighborhood.str.lower().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we want to replace the spaces on the neighbourhood with a `_`, we can do so with `.replace()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.neighborhood = df.neighborhood.str.replace(\" \", \"_\").str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many string methods available, for example, we can use `.str.strip()` to remove the `/apt` at the end of the room_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.room_type.str.strip(\"/apt\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.str.cat` to interpolate strings. For example, if we want to set the index to `room_id_host_id` we can do so as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()\n",
    "df.index = df.index.astype(str)\n",
    "df.host_id = df.host_id.astype(str)\n",
    "df.index = df.index.str.cat(df.host_id.astype(str), sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename\n",
    "\n",
    "`.rename` allows us to rename indices, either the row index or the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rename columns very easily this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"neighborhood\": \"neighbourhood\", \"reviews\": \"number_reviews\"}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also rename the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed_neighbourhood = df.set_index(\"neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed_neighbourhood.rename({\"Belém\": \"Belem\", \"Santa Maria Maior\": \"Saint Mary\"}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`replace` allows us to replace values on the data (not the indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we want to change the numerical values on the overall_satisfaction column to an ordinal scale we can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\n",
    "    {\n",
    "        5:\"Best\",\n",
    "        4: \"Good\",\n",
    "        3: \"OK\",\n",
    "        2: \"Not so great\",\n",
    "        1: \"Worst\",\n",
    "        0: \"No Information\"\n",
    "    }).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default  `replace` replaces the values in all the columns. We can replace values only on one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.overall_satisfaction.replace(\n",
    "    {\n",
    "        5:\"Best\",\n",
    "        4: \"Good\",\n",
    "        3: \"OK\",\n",
    "        2: \"Not so great\",\n",
    "        1: \"Worst\",\n",
    "        0: \"No Information\"\n",
    "    }).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by allows us to group the dataframe based on its features.\n",
    "\n",
    "More precisely, Pandas  group by applies a process called [split-apply-combine](https://pandas.pydata.org/pandas-docs/stable/groupby.html).\n",
    "* split: Separates the dataframe based on the specified groups\n",
    "* apply: Applies a function to each one of the groups\n",
    "* combine: Combinanes the results into a new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we want to know how many listings every host has we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"host_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`group_by` returns a `DataFrameGroupBy `, which is a special dataframe object that separates the dataframe by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"room_id\", \"host_id\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_by_host = df[[\"room_id\", \"host_id\"]].groupby(\"host_id\")\n",
    "listings_by_host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can count them with `count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listings_by_host.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the columns we use to group become the index, if we want them to stay as columns we can use the argument `as_index = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "properties_by_owner = df[[\"room_id\", \"host_id\"]].groupby(\"host_id\", as_index=False)\n",
    "properties_by_owner.count().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can calculate the average listing price by room type and host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_price = df.groupby([\"host_id\", \"room_type\"])[[\"price\"]].mean()\n",
    "average_price.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge\n",
    "\n",
    "`merge` allows us to join two dataframes based on one or two columns, similar to a SQL JOIN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to load an additional dataset that contains the population in every Lisbon district (taken from [here](https://www.citypopulation.de/php/portugal-lisboa.php))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()\n",
    "populations = pd.read_csv(\"data/population_lisboa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do a merge between the Airbnb listings and the populations.\n",
    "\n",
    "merge works as follows:\n",
    "\n",
    "```\n",
    "pd.merge(left_dataframe,right_dataframe,join_type)\n",
    "```\n",
    "\n",
    "merge has different parameters:\n",
    "\n",
    "`left_on` is the name of the column for the left dataframe.\n",
    "`right_on` is the name of the column for the right dataframe.\n",
    "`how` specifies the join type, how to make the union:\n",
    " - `full` takes all rows for both dataframes whether the values on the join columns exist on both dataframes or not.\n",
    " - `inner` takes only the rows on the dataframews where the values on the join columns exist on both dataframes. This is the default value.\n",
    " - `left` takes all rows for the left dataframe whether the values on the join columns exist on it dataframes or not.\n",
    " - `right` the opposite of `left`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_with_pop = pd.merge(df, populations, left_on=\"neighborhood\", right_on=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_with_pop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_with_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how merge works.\n",
    "\n",
    "We can see the original number of neighbourhoods by doing `unique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoud_list_all = df.neighborhood.unique()\n",
    "neighborhoud_list_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neighborhoud_list_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are 24 unique neighbourhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many neighbourhoods we get when we do the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoud_list_merge = listings_with_pop.neighborhood.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neighborhoud_list_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is a neighbourhood missing! Maybe there is one missing on the population dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(neighborhoud_list_all) - set(neighborhoud_list_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see *São Vicente* doesn't exist on the population dataset. When we do a merge, we do an `inner` merge by default, and it removes those rows whose shared column/s don't match. In this example `*São Vicente*` exists on the Airbnbn `neighborhood` column but doesn't exist on the populations dataframe `name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_with_pop[listings_with_pop.neighborhood==\"São Vicente\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular example, the reference dataframe is the Airbnb, and we are just adding additional data to it. So we would rather keep those listings in São Vicente even though we wont have population information for them. In this case we will do a left merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_with_pop = pd.merge(df, populations, left_on=\"neighborhood\", right_on=\"name\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we kept all the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_with_pop[listings_with_pop.neighborhood==\"São Vicente\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.crosstab` allows us to cross data and calculate how many observations fall under two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.neighborhood, df.room_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the argument `normalize` to get percentages instead of totals:\n",
    "- `normalize=\"all\"` returns total percentages (% of the total dataframe) \n",
    "- `normalize=\"index\"` returns percentages per row\n",
    "- `normalize=\"columns\"` returns percentages per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.neighborhood, df.room_type, normalize=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the percentage of listings per neibourhood broken down by room type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.neighborhood, df.room_type, normalize=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see how many of each room type are on each neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.neighborhood, df.room_type, normalize=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Table\n",
    "\n",
    "`pivot_table` performs the same function as pivot tables in Excel, it turns rows into columns based on the values on the columns (it \"pivots\" the data).\n",
    "\n",
    "this function has different arguments:\n",
    "\n",
    "- `index`: the columns we want to turn into rows of the pivot table\n",
    "- `columns`: the columns we want to turn into columns\n",
    "- `values`: the columns we want to aggregate\n",
    "- `aggfunc`: the aggregate function applied to the values (mean by default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we want to calculate the average satisfaction by room_type for each neighbourhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, index=\"neighborhood\", \n",
    "                   columns=\"room_type\", \n",
    "                   values=[\"overall_satisfaction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have the following dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data = pd.DataFrame({\n",
    "    \"worked_hours\": [5, 5.2, \"sick\", 8, 10],\n",
    "    \"work_date\": [\"2018-01-02\", \"208-01-02\", \"2018-01-04\", \"2018-01-05\", \"2018-01-06\"],\n",
    "    \"employee\": [\"Manuel\", \"John\", \"Manuel\", \"John\", \"Manuel\"]\n",
    "})\n",
    "\n",
    "unprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the dataset, it is obvious that the variable `work_date` is a date, `worked_hours` is a number and `employee` is a string. However, because of errors on the data, Pandas has considered all columns as strings (object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn columns into numbers with `pd.to_numeric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(unprocessed_data.worked_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `to_numeric` fails if any value can't be converted. We can change the conversion strategy by specifying the error strategy (with the argument `errors`). For example, if we use `errors=\"coerce\"` pandas will convert those values it can and will convert the rest to null values (NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(unprocessed_data.worked_hours, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same way, we can convert dates to datetime objects (a datatype specific for dates). We can use `pd.to_datetime` to do so. It will coerce invalid dates into nulls (NaT, `not a time`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(unprocessed_data.work_date, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma podemos convertir el dataframe a su formato correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data[\"work_date\"] = pd.to_datetime(unprocessed_data.work_date, errors=\"coerce\")\n",
    "unprocessed_data[\"worked_hours\"] = pd.to_numeric(unprocessed_data.worked_hours, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datetime columns have additional functionality, similarly to the `str.` methods with strings. We can access the datetime methods via the attribute `.dt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can find the day of week with `.dt.dayofweek`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data.work_date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data.work_date.dt.weekday_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can encode categorical variables in two ways, regular objects (strings), or **category**. \n",
    "Pandas provide us with a category dtype for categorical data:\n",
    "\n",
    "    Easily identify and signal categorical columns for processing and other Python libraries\n",
    "    Converting a string variable with a few different values to a categorical variable saves memory\n",
    "    By converting to a categorical we can specify an order on the categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(index=True, deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can encode the room type and neighbourhood as categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\"room_type\": \"category\", \"neighborhood\": \"category\"})\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see we get additional information when describing categories, and not only that, the 2 columns now take significantly less memory space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(index=True, deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category type columns have a way to easily convert their value (or level, that means the string they represent) to a number (that pandas uses to store them internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.neighborhood.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also works well for ordinal variables. We can assign an order to a categorical variable. For example, we can set the variable `room_type` as an ordinal variable `(Entire Home > Private Room > Shared Room)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.room_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default a categorical column is not ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.room_type.cat.ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign the order by doing `.cat.set_categories` and passing the list of levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.room_type = df.room_type.cat.set_categories([\"Shared room\",\"Private room\", \"Entire home/apt\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.room_type.cat.ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now because we know the sorting order of the categories, we can filter the ordinal column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.room_type>\"Shared room\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading a csv, we can also specify dtypes so we can directly create category columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, dtype={\n",
    "                                            \"room_type\": \"category\",\n",
    "                                            \"neighborhood\": \"category\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
